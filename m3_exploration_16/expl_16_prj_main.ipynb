{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb1118d5",
   "metadata": {},
   "source": [
    "# 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d33fa9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58ed31e",
   "metadata": {},
   "source": [
    "# Step 1. 데이터 수집하기\n",
    "\n",
    "---\n",
    "\n",
    "한국어 챗봇 데이터는 송영숙님이 공개한 챗봇 데이터를 사용합니다.\n",
    "\n",
    "이 데이터는 아래의 링크에서 다운로드할 수 있습니다.\n",
    "\n",
    "- [songys/Chatbot_data](https://github.com/songys/Chatbot_data/blob/master/ChatbotData.csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0a1e93d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/ChatbotData .csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "92b61489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11823 entries, 0 to 11822\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Q       11823 non-null  object\n",
      " 1   A       11823 non-null  object\n",
      " 2   label   11823 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 277.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bc3c0021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Q            A  label\n",
       "0        12시 땡!   하루가 또 가네요.      0\n",
       "1   1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2  3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "24411f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['Q'], data['A'], test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "98ddf287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10640,), (10640,), (1183,), (1183,))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a792f6",
   "metadata": {},
   "source": [
    "\n",
    "# Step 2. 데이터 전처리하기\n",
    "\n",
    "---\n",
    "\n",
    "영어 데이터와는 전혀 다른 데이터인 만큼 영어 데이터에 사용했던 전처리와 일부 동일한 전처리도 필요하겠지만 전체적으로는 다른 전처리를 수행해야 할 수도 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81bfed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "\n",
    "    # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "    # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "    # student와 온점 사이에 거리를 만듭니다.\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e3a80762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3727: 이상한 소문이 돌아\n",
      "3727: 소문은 소문일 뿐이에요 .\n"
     ]
    }
   ],
   "source": [
    "rnd_idx = np.random.randint(0, X_train.shape[0])\n",
    "print('{}: {}'.format(rnd_idx, preprocess_sentence(X_train[rnd_idx])))\n",
    "print('{}: {}'.format(rnd_idx, preprocess_sentence(y_train[rnd_idx])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49e7752",
   "metadata": {},
   "source": [
    "# Step 3. SubwordTextEncoder 사용하기\n",
    "\n",
    "---\n",
    "\n",
    "한국어 데이터는 형태소 분석기를 사용하여 토크나이징을 해야 한다고 많은 분이 알고 있습니다. 하지만 여기서는 형태소 분석기가 아닌 위 실습에서 사용했던 내부 단어 토크나이저인 `SubwordTextEncoder`를 그대로 사용해보세요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d340b57",
   "metadata": {},
   "source": [
    "## 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "cfebaecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(X_train + y_train, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0cfef637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f5eef1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [7716]\n",
      "END_TOKEN의 번호 : [7717]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "cc40017c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7718\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b70a76",
   "metadata": {},
   "source": [
    "## 정수 인코딩 & 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "28ef8d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3727. 질문: [1659, 6482, 7492, 1166]\n",
      "3727. 답변: [3922, 24, 3922, 83, 540, 7506]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('{}. 질문: {}'.format(rnd_idx, tokenizer.encode(X_train[rnd_idx])))\n",
    "print('{}. 답변: {}'.format(rnd_idx, tokenizer.encode(y_train[rnd_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a141c5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_len = X_train.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8edd812a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.850e+02, 9.980e+02, 2.312e+03, 1.720e+03, 2.046e+03, 1.338e+03,\n",
       "        8.400e+02, 3.670e+02, 3.850e+02, 2.040e+02, 1.310e+02, 4.700e+01,\n",
       "        3.000e+01, 1.900e+01, 7.000e+00, 3.000e+00, 5.000e+00, 1.000e+00,\n",
       "        0.000e+00, 1.000e+00]),\n",
       " array([ 1.  ,  3.75,  6.5 ,  9.25, 12.  , 14.75, 17.5 , 20.25, 23.  ,\n",
       "        25.75, 28.5 , 31.25, 34.  , 36.75, 39.5 , 42.25, 45.  , 47.75,\n",
       "        50.5 , 53.25, 56.  ]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(X_len[:-1], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b5366909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10052    40\n",
       "11556    45\n",
       "11248    46\n",
       "8903     46\n",
       "11451    42\n",
       "11348    42\n",
       "10605    41\n",
       "11011    48\n",
       "11462    41\n",
       "11769    43\n",
       "9519     41\n",
       "11053    46\n",
       "9506     41\n",
       "11044    47\n",
       "9273     43\n",
       "8527     44\n",
       "11810    56\n",
       "Name: Q, dtype: int64"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_len[X_len >= 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b1283c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9983084296588667\n"
     ]
    }
   ],
   "source": [
    "under_val = len(X_len[X_len < 40])\n",
    "print(under_val / df_train_q.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7f102766",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "58c516dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "        # 최대 길이 40이하인 경우에만 데이터셋으로 허용\n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "\n",
    "    # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "    return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7affb184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 7718\n",
      "필터링 후의 샘플 개수: 10640\n",
      "필터링 후의 샘플 개수: 10640\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(X_train, y_train)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b113a5",
   "metadata": {},
   "source": [
    "# Step 4. 모델 구성하기\n",
    "\n",
    "---\n",
    "\n",
    "위 실습 내용을 참고하여 트랜스포머 모델을 구현합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bcc85b",
   "metadata": {},
   "source": [
    "## Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d2b02947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "        # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c829255",
   "metadata": {},
   "source": [
    "## Scaled Dot Product Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a3a075f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # 가중치를 정규화\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # 패딩에 마스크 추가\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # softmax적용\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a06a59",
   "metadata": {},
   "source": [
    "## Multi Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a9b320f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # linear layers\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다.\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 스케일드 닷-프로덕트 어텐션 함수\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다.\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))\n",
    "\n",
    "        # final linear layer\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0502d280",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "08be4907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0f681426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d72696",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5d1d444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 첫번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "          d_model, num_heads, name=\"attention\")({\n",
    "              'query': inputs,\n",
    "              'key': inputs,\n",
    "              'value': inputs,\n",
    "              'mask': padding_mask\n",
    "          })\n",
    "\n",
    "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "          epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 두번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "          epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "          inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "444adda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # num_layers만큼 쌓아올린 인코더의 층.\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661688c2",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5e939355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "          shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 첫번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "          d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "              'query': inputs,\n",
    "              'key': inputs,\n",
    "              'value': inputs,\n",
    "              'mask': look_ahead_mask\n",
    "          })\n",
    "\n",
    "    # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "          epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 두번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "          d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "              'query': attention1,\n",
    "              'key': enc_outputs,\n",
    "              'value': enc_outputs,\n",
    "              'mask': padding_mask\n",
    "          })\n",
    "\n",
    "    # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "    # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "          epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 세번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "          epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "          inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "          outputs=outputs,\n",
    "          name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f668ed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "    # 패딩 마스크\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e2576f",
   "metadata": {},
   "source": [
    "## Teacher Forcing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "54c3e016",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024eccf1",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "90d5b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더에서 패딩을 위한 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 디코더에서 미래의 토큰을 마스크하기위해서 사용합니다.\n",
    "    # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 두번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "    # 디코더에서 패딩을 위한 마스크\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더\n",
    "    enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "    # 디코더\n",
    "    dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d5a5ab50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3030016     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3557376     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 7718)   1983526     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,570,918\n",
      "Trainable params: 8,570,918\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b980988d",
   "metadata": {},
   "source": [
    "## Loss, Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e7044459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7bfef122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3eb0a1",
   "metadata": {},
   "source": [
    "## Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f694e308",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0f01b588",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cbc1a5",
   "metadata": {},
   "source": [
    "## Model Compile & Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6615e20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7a7aa05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "167/167 [==============================] - 16s 54ms/step - loss: 1.4679 - accuracy: 0.0212\n",
      "Epoch 2/50\n",
      "167/167 [==============================] - 9s 54ms/step - loss: 1.2260 - accuracy: 0.0468\n",
      "Epoch 3/50\n",
      "167/167 [==============================] - 9s 54ms/step - loss: 1.0437 - accuracy: 0.0503\n",
      "Epoch 4/50\n",
      "167/167 [==============================] - 9s 54ms/step - loss: 0.9598 - accuracy: 0.0536\n",
      "Epoch 5/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.9029 - accuracy: 0.0566\n",
      "Epoch 6/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.8481 - accuracy: 0.0599\n",
      "Epoch 7/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.7875 - accuracy: 0.0648\n",
      "Epoch 8/50\n",
      "167/167 [==============================] - 9s 54ms/step - loss: 0.7214 - accuracy: 0.0716\n",
      "Epoch 9/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.6502 - accuracy: 0.0796\n",
      "Epoch 10/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.5737 - accuracy: 0.0881\n",
      "Epoch 11/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.4943 - accuracy: 0.0976\n",
      "Epoch 12/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.4151 - accuracy: 0.1078\n",
      "Epoch 13/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.3387 - accuracy: 0.1184\n",
      "Epoch 14/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.2667 - accuracy: 0.1294\n",
      "Epoch 15/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.2043 - accuracy: 0.1392\n",
      "Epoch 16/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.1505 - accuracy: 0.1489\n",
      "Epoch 17/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.1086 - accuracy: 0.1565\n",
      "Epoch 18/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0781 - accuracy: 0.1622\n",
      "Epoch 19/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0597 - accuracy: 0.1652\n",
      "Epoch 20/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0489 - accuracy: 0.1669\n",
      "Epoch 21/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0429 - accuracy: 0.1679\n",
      "Epoch 22/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0391 - accuracy: 0.1684\n",
      "Epoch 23/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0372 - accuracy: 0.1688\n",
      "Epoch 24/50\n",
      "167/167 [==============================] - 9s 54ms/step - loss: 0.0357 - accuracy: 0.1689\n",
      "Epoch 25/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0347 - accuracy: 0.1690\n",
      "Epoch 26/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0295 - accuracy: 0.1702\n",
      "Epoch 27/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0271 - accuracy: 0.1707\n",
      "Epoch 28/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0245 - accuracy: 0.1714\n",
      "Epoch 29/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0215 - accuracy: 0.1722\n",
      "Epoch 30/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0196 - accuracy: 0.1726\n",
      "Epoch 31/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0178 - accuracy: 0.1731\n",
      "Epoch 32/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0164 - accuracy: 0.1734\n",
      "Epoch 33/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0144 - accuracy: 0.1740\n",
      "Epoch 34/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0141 - accuracy: 0.1741\n",
      "Epoch 35/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0128 - accuracy: 0.1745\n",
      "Epoch 36/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0123 - accuracy: 0.1746\n",
      "Epoch 37/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0112 - accuracy: 0.1748\n",
      "Epoch 38/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0104 - accuracy: 0.1750\n",
      "Epoch 39/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0102 - accuracy: 0.1751\n",
      "Epoch 40/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0097 - accuracy: 0.1751\n",
      "Epoch 41/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0085 - accuracy: 0.1754\n",
      "Epoch 42/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0090 - accuracy: 0.1753\n",
      "Epoch 43/50\n",
      "167/167 [==============================] - 9s 54ms/step - loss: 0.0081 - accuracy: 0.1756\n",
      "Epoch 44/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0078 - accuracy: 0.1756\n",
      "Epoch 45/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0074 - accuracy: 0.1758\n",
      "Epoch 46/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0071 - accuracy: 0.1757\n",
      "Epoch 47/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0074 - accuracy: 0.1757\n",
      "Epoch 48/50\n",
      "167/167 [==============================] - 9s 54ms/step - loss: 0.0063 - accuracy: 0.1759\n",
      "Epoch 49/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0064 - accuracy: 0.1759\n",
      "Epoch 50/50\n",
      "167/167 [==============================] - 9s 53ms/step - loss: 0.0059 - accuracy: 0.1761\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "history = model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4ebfec",
   "metadata": {},
   "source": [
    "## Visualisation - Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "cbe51d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a subplot with 2 rows and 1 column\n",
    "fig, ax = plt.subplots(2, 1, figsize=(8, 6))\n",
    "\n",
    "# Plot loss values on the first subplot\n",
    "ax[0].plot(history.history['loss'], 'r')\n",
    "ax[0].set_title('Model Loss')\n",
    "ax[0].set_ylabel('Loss')\n",
    "\n",
    "# Plot accuracy values on the second subplot\n",
    "ax[1].plot(history.history['accuracy'], 'b')\n",
    "ax[1].set_title('Model Accuracy')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846618d5",
   "metadata": {},
   "source": [
    "> 에포크 200회 결과 50회 정도에서 더 나아지지 않음.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686c88c4",
   "metadata": {},
   "source": [
    "# Step 5. 모델 평가하기\n",
    "\n",
    "---\n",
    "\n",
    "Step 1에서 선택한 전처리 방법을 고려하여 입력된 문장에 대해서 대답을 얻는 예측 함수를 만듭니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b8a8cfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "    # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "    # 처음에는 예측한 내용이 없으므로 시작 토큰만 별도 저장. ex) 8331\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "    # 디코더의 인퍼런스 단계\n",
    "    for i in range(MAX_LENGTH):\n",
    "        # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "\n",
    "        # 현재 예측한 단어의 정수\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "\n",
    "        # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "        # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d2cc87b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "    # 입력 문장에 대해서 디코더를 동작시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "    prediction = decoder_inference(sentence)\n",
    "\n",
    "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d5882144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat(number=10):\n",
    "    for i in range(10):\n",
    "        rnd_i = np.random.randint(0, X_test.shape[0])\n",
    "        print('Q: {}'.format(X_test.iloc[rnd_i]))\n",
    "        print('PRED.A: {}'.format(sentence_generation(X_test.iloc[rnd_i])))\n",
    "        print('REAL.A: {}'.format(y_test.iloc[rnd_i]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd211d16",
   "metadata": {},
   "source": [
    "## epoch - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "713c7e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 운동 좀 잘 하고 싶다. 진짜\n",
      "A: 뭐든 시작해보면 좋을 거예요.\n",
      "\n",
      "Q: 먼저 인사할까 했는데 짝녀가 먼저 인사해줬어.\n",
      "A: 다정한게 좋을 거예요.\n",
      "\n",
      "Q: 오늘도 공기가 뿌얘\n",
      "A: 운동하고 오세요.\n",
      "\n",
      "Q: 사랑해 보고싶어\n",
      "A: 할 수 있을 거예요.\n",
      "\n",
      "Q: 유부녀 좋아하면 안되지?\n",
      "A: 저도 모르겠어요.\n",
      "\n",
      "Q: 인터넷 쇼핑몰에서 바지 샀는데 망함\n",
      "A: 이해하기 힘드니까요.\n",
      "\n",
      "Q: 내가 좋아하는 사람이 나 좋아해줬으면 좋겠다\n",
      "A: 먼저 다가가 보세요.\n",
      "\n",
      "Q: 친구인데 고백해도 될까?\n",
      "A: 고민 하고 있으면 썸의 가능성이 높겠네요.\n",
      "\n",
      "Q: 썸은 좋았는데 연애는 별로\n",
      "A: 그 누구도 아닌 자기 걸음을 걸으세요.\n",
      "\n",
      "Q: 남자친구가 진짜 잘 챙겨줘\n",
      "A: 그래도 상관없어요. 칭찬해주고 싶네요.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_chat(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc9629c",
   "metadata": {},
   "source": [
    "## epoch - 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "163d612a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 약 챙겨 먹어야지\n",
      "A: 제길.\n",
      "\n",
      "Q: 이별극복후 새로운 설렘\n",
      "A: 새로운 시작 응원해요.\n",
      "\n",
      "Q: 헤어지지 말자더니 놔버린 나쁜놈\n",
      "A: 마음 단단히 잡길 바랄게요.\n",
      "\n",
      "Q: 등산할까\n",
      "A: 그러게 말이에요.\n",
      "\n",
      "Q: 술 먹으면 연락이 안돼\n",
      "A: 혼자 힘들어하지 마세요.\n",
      "\n",
      "Q: 헤어진지 5개월차 꿀인생삽니다\n",
      "A: 항상 좋아했나봐요.\n",
      "\n",
      "Q: 이별후 그리움이 생생한 오늘\n",
      "A: 상대의 의견도 물어보세요.\n",
      "\n",
      "Q: 노는 거 좋아하는 사람은 좋아하면 힘들거야.\n",
      "A: 지금은 괜찮지만 힘들 거예요.\n",
      "\n",
      "Q: 오래 연애하고 싶어.\n",
      "A: 좋은 소식이네요.\n",
      "\n",
      "Q: 7년사귄 남자친구에게 배신당했어.\n",
      "A: 저는 저에게 투자하는 시간을 가져요. 예를들면 운동이나 여행같이 잡념을 없앨 수 있는 일들이요.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_chat(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8765c8c6",
   "metadata": {},
   "source": [
    "## epoch - 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "f9ccfb1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 의욕이 없어\n",
      "PRED.A: 가벼운 산책을 해보세요.\n",
      "REAL.A: 가벼운 산책을 해보세요.\n",
      "\n",
      "Q: 독학하려니까 힘들어\n",
      "PRED.A: 신경 말을 한 사람이 가장 이상할 거예요.\n",
      "REAL.A: 더 깊은 공부할 수 있을 거예요.\n",
      "\n",
      "Q: 오늘 상 받았다\n",
      "PRED.A: 축하드려요.\n",
      "REAL.A: 축하드려요.\n",
      "\n",
      "Q: 오랜만에 쇼핑\n",
      "PRED.A: 제 선물 사오세요.\n",
      "REAL.A: 득템했길 바라요.\n",
      "\n",
      "Q: 마지막이겠죠\n",
      "PRED.A: 고민은 누구나 해요.\n",
      "REAL.A: 마지막이 아닐 지도 몰라요.\n",
      "\n",
      "Q: 뷔페 가고 싶어\n",
      "PRED.A: 저도 딸기 좋아해요. 같이 가요.\n",
      "REAL.A: 저도 딸기 좋아해요. 같이 가요.\n",
      "\n",
      "Q: 아쉬움만 남아\n",
      "PRED.A: 이별 뒤엔 아쉬움이 따를뿐이죠.\n",
      "REAL.A: 더 많이 배웠길 바라요.\n",
      "\n",
      "Q: 사랑받고싶어\n",
      "PRED.A: 잠시 쉬어도 괜찮아요.\n",
      "REAL.A: 먼저 사랑한다고 말해보세요.\n",
      "\n",
      "Q: 여름 빨리 지나갔으면\n",
      "PRED.A: 공부한 만큼 나올 거예요.\n",
      "REAL.A: 곧 지나갑니다.\n",
      "\n",
      "Q: 이 사랑이 마지막 사랑이었으면\n",
      "PRED.A: 그 울어도 돼요.\n",
      "REAL.A: 후회하지 않을 사랑 해보세요.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_chat(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b85b2c",
   "metadata": {},
   "source": [
    "> 예측값, 실제값 비교\n",
    ">   - 어떻게 에측값이 실제값과 같을 수 있지?  \n",
    ">   - 학습 데이터와 내용이 섞여있는건가?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
