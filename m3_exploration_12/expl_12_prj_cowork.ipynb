{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e605dc10",
   "metadata": {
    "id": "e04b0af9"
   },
   "source": [
    "# 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08565e16",
   "metadata": {
    "id": "cN_T2ttyiTzB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.layers import AdditiveAttention\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import urllib\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "\n",
    "import summa\n",
    "from summa.summarizer import summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209e5443",
   "metadata": {
    "id": "8db2f29a"
   },
   "source": [
    "# Step 1. 데이터 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd84a26",
   "metadata": {
    "id": "CwcPbKDtb1Pp"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c82a1098",
   "metadata": {
    "id": "qImdOBEViwis"
   },
   "outputs": [],
   "source": [
    "data_path = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03288a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_headlines.json  expl_12_prj_cowork.ipynb\tnews_summary_more.csv\r\n",
      "clean_text.json       expl_12_prj_main.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2021be4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# request data\n",
    "\n",
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd883a95",
   "metadata": {
    "collapsed": true,
    "id": "55E8X1XgirUC"
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 2 fields in line 218223, saw 7\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_58/3958630104.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'news_summary_more.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'iso-8859-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 2 fields in line 218223, saw 7\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "badd28be",
   "metadata": {
    "id": "JInHbEnrjYfx"
   },
   "outputs": [],
   "source": [
    "data['headlines_original'] = data['headlines']\n",
    "data['text_original'] = data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b15df2c2",
   "metadata": {
    "id": "muBxsNUUjN3l"
   },
   "outputs": [],
   "source": [
    "with open(data_path + 'clean_text.json', 'r') as file:\n",
    "    loaded_text = json.load(file)\n",
    "\n",
    "with open(data_path + 'clean_headlines.json', 'r') as file:\n",
    "    loaded_headlines = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea111221",
   "metadata": {
    "id": "43e44871"
   },
   "source": [
    "# Step 2. 데이터 전처리하기 (추상적 요약)\n",
    "\n",
    "실습에서 사용된 전처리를 참고하여 각자 필요하다고 생각하는 전처리를 추가 사용하여 텍스트를 정규화 또는 정제해 보세요. 만약, 불용어 제거를 선택한다면 상대적으로 길이가 짧은 요약 데이터에 대해서도 불용어를 제거하는 것이 좋을지 고민해 보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2307cc",
   "metadata": {
    "id": "573a8704"
   },
   "source": [
    "## - 중복 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b72e6dc0",
   "metadata": {
    "id": "ZDcb4wdaltqP"
   },
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset=['headlines'], inplace=True) # 헤드라인은 중복될 수도 있음\n",
    "data.drop_duplicates(subset=['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba365328",
   "metadata": {
    "id": "8msZNzHLl93w"
   },
   "outputs": [],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ab329b8",
   "metadata": {
    "id": "MMIArxykmEGz"
   },
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "\n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f70eaf41",
   "metadata": {
    "id": "1amj7rY6mJlh"
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - '/aiffel/nltk_data'\n    - '/opt/conda/nltk_data'\n    - '/opt/conda/share/nltk_data'\n    - '/opt/conda/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords.zip/stopwords/\u001b[0m\n\n  Searched in:\n    - '/aiffel/nltk_data'\n    - '/opt/conda/nltk_data'\n    - '/opt/conda/share/nltk_data'\n    - '/opt/conda/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_58/574572401.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'headlines'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mclean_headlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_58/2940928949.py\u001b[0m in \u001b[0;36mpreprocess_sentence\u001b[0;34m(sentence, remove_stopwords)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# 불용어 제거 (Text)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mremove_stopwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m# 불용어 미제거 (Summary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_58/2940928949.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# 불용어 제거 (Text)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mremove_stopwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m# 불용어 미제거 (Summary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{self.__name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - '/aiffel/nltk_data'\n    - '/opt/conda/nltk_data'\n    - '/opt/conda/share/nltk_data'\n    - '/opt/conda/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# 전체 Headlines 데이터에 대한 전처리\n",
    "clean_headlines = []\n",
    "\n",
    "for text in data['headlines']:\n",
    "    clean_headlines.append(preprocess_sentence(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c58fcb",
   "metadata": {
    "id": "bsoA2stKmLVT"
   },
   "outputs": [],
   "source": [
    "# 전체 Text 데이터에 대한 전처리\n",
    "clean_text = []\n",
    "\n",
    "for text in data['text']:\n",
    "    clean_text.append(preprocess_sentence(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "580fd21c",
   "metadata": {
    "id": "lOEpq7c1mPGD"
   },
   "outputs": [],
   "source": [
    "data['headlines'] = loaded_headlines\n",
    "data['text'] = loaded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34d83db3",
   "metadata": {
    "id": "bbg1gTrymdDa"
   },
   "outputs": [],
   "source": [
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f4ee5b",
   "metadata": {
    "id": "e7a31c25"
   },
   "source": [
    "## - 소문자화, 불용어 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40307dba",
   "metadata": {
    "id": "3746d650"
   },
   "source": [
    "## - 문자 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d077113d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EYqIxN0lmi_B",
    "outputId": "6e0d4089-45ac-477e-d32e-c45167eba7e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 60\n",
      "텍스트의 평균 길이 : 35.10029309397326\n",
      "헤드라인의 최소 길이 : 1\n",
      "헤드라인의 최대 길이 : 13\n",
      "헤드라인의 평균 길이 : 7.136787364393153\n"
     ]
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "headlines_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('헤드라인의 최소 길이 : {}'.format(np.min(headlines_len)))\n",
    "print('헤드라인의 최대 길이 : {}'.format(np.max(headlines_len)))\n",
    "print('헤드라인의 평균 길이 : {}'.format(np.mean(headlines_len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff414a7d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "3LPt3seymruk",
    "outputId": "376dd9e1-2871-4f07-8485-45317b4390bd"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3, 3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(headlines_len)\n",
    "plt.title('Headlines')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46b2d8ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "8r_zuk6hmuuD",
    "outputId": "f8f10938-9730-4aa5-f5d4-626c65fa29ba"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Headlines')\n",
    "plt.hist(headlines_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "592b0bd3",
   "metadata": {
    "id": "5x94CoS7m04B"
   },
   "outputs": [],
   "source": [
    "text_max_len = 50\n",
    "headlines_max_len = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "036849cc",
   "metadata": {
    "id": "cI19fTyem5EV"
   },
   "outputs": [],
   "source": [
    "def print_threshold_ratio(max_len, data_len):\n",
    "    total = len(data_len)\n",
    "    under_threshold = len([i for i in data_len if i <= max_len])\n",
    "    over_threshold = len([i for i in data_len if i > max_len])\n",
    "    print('under-threshold data: ', under_threshold)\n",
    "    print('over-threshold data: ', over_threshold)\n",
    "    print('threshold ratio: %.2f' % (under_threshold / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "259052b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1AcXPSBSm8Sx",
    "outputId": "155c91c9-92e4-4318-9839-0a2a92e23cf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:\n",
      "under-threshold data:  98248\n",
      "over-threshold data:  14\n",
      "threshold ratio: 1.00\n",
      "headlines:\n",
      "under-threshold data:  98049\n",
      "over-threshold data:  213\n",
      "threshold ratio: 1.00\n"
     ]
    }
   ],
   "source": [
    "print('text:')\n",
    "print_threshold_ratio(text_max_len, text_len)\n",
    "print('headlines:')\n",
    "print_threshold_ratio(headlines_max_len, headlines_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1010b29c",
   "metadata": {
    "id": "eLB40yOqnBeO"
   },
   "outputs": [],
   "source": [
    "data = data[data['text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['headlines'].apply(lambda x: len(x.split()) <= headlines_max_len)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dedfca",
   "metadata": {
    "id": "2d65c763"
   },
   "source": [
    "## - SOS, EOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06a0050f",
   "metadata": {
    "id": "tMWpStKgnGZq"
   },
   "outputs": [],
   "source": [
    "data.loc[:, 'decoder_input'] = data['headlines'].apply(lambda x : 'sostoken ' + x)\n",
    "data.loc[:, 'decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87d61907",
   "metadata": {
    "id": "AyxI9A-hnMXy"
   },
   "outputs": [],
   "source": [
    "encoder_input = np.array(data['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블\n",
    "text_original = np.array(data['text_original'])  # 원본 텍스트 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9eecc6cc",
   "metadata": {
    "id": "mJqnB8E-nR8K"
   },
   "outputs": [],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e2328de",
   "metadata": {
    "id": "Z65830zJnZta"
   },
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]\n",
    "text_original = text_original[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "696e5e8d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mGNiohtAncGq",
    "outputId": "c33d2161-4bf1-44b4-aa97-768edf4d8508"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 19607\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :', n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e48339a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-tAa-9xynfI2",
    "outputId": "7a18d8c1-ef89-45ea-bb6d-757c083752bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 78429\n",
      "훈련 레이블의 개수 : 78429\n",
      "테스트 데이터의 개수 : 19607\n",
      "테스트 레이블의 개수 : 19607\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "text_original_train = text_original[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "text_original_test = text_original[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f9cf3d",
   "metadata": {
    "id": "68727ed3"
   },
   "source": [
    "## - 정수 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de21f357",
   "metadata": {
    "id": "48d41144"
   },
   "source": [
    "단어 빈도에 따른 데이터 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c55ebcc",
   "metadata": {
    "id": "3Xjirv8znlI3"
   },
   "outputs": [],
   "source": [
    "def print_word_frequency(input_train, threshold_value=0):\n",
    "\n",
    "    tokenizer = Tokenizer() # 토크나이저 정의\n",
    "    tokenizer.fit_on_texts(input_train) # 입력된 데이터로부터 단어 집합 생성\n",
    "\n",
    "    threshold = threshold_value\n",
    "    total_cnt = len(tokenizer.word_index) # 단어의 수\n",
    "    rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "    total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "    rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "    # 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "    for key, value in tokenizer.word_counts.items():\n",
    "        total_freq = total_freq + value\n",
    "\n",
    "        # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "        if(value < threshold):\n",
    "            rare_cnt = rare_cnt + 1\n",
    "            rare_freq = rare_freq + value\n",
    "\n",
    "    print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "    print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "    print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "    print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "    print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b73c6c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ZH9kDzPnoZx",
    "outputId": "5c3de291-9634-44ea-d8ad-9e6c84855234"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 69353\n",
      "등장 빈도가 49번 이하인 희귀 단어의 수: 62212\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 7141\n",
      "단어 집합에서 희귀 단어의 비율: 89.7034014390149\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 13.540613444846732\n"
     ]
    }
   ],
   "source": [
    "# 인코더 단어 빈도\n",
    "print_word_frequency(encoder_input_train, threshold_value=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77805df4",
   "metadata": {
    "id": "TRxyjeEYnvWB"
   },
   "outputs": [],
   "source": [
    "src_vocab = 7000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 7,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "751406ff",
   "metadata": {
    "id": "3vPyevRnnysj"
   },
   "outputs": [],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train)\n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c8770b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g0iTPs3on5iB",
    "outputId": "fa9eea7f-eb0f-434f-9ee2-0ce2c64bc253"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 29732\n",
      "등장 빈도가 19번 이하인 희귀 단어의 수: 25023\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 4709\n",
      "단어 집합에서 희귀 단어의 비율: 84.16184582268264\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 15.021414787970066\n"
     ]
    }
   ],
   "source": [
    "# 디코더 단어 빈도\n",
    "print_word_frequency(decoder_input_train, threshold_value=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "442d8d01",
   "metadata": {
    "id": "U4lbHEXhn26h"
   },
   "outputs": [],
   "source": [
    "tar_vocab = 5000\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab)\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f470161e",
   "metadata": {
    "id": "I0xU73VBo0LR"
   },
   "outputs": [],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train)\n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f73d075",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wRhAD6f4o5pw",
    "outputId": "e10167df-7ba1-4954-e8e9-9f9f85c6f457"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 13\n",
      "삭제할 테스트 데이터의 개수 : 4\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9416f5d",
   "metadata": {
    "id": "lWxEPHvSo9nW"
   },
   "outputs": [],
   "source": [
    "def drop_onesentence(data, drop_data):\n",
    "    return [sentence for index, sentence in enumerate(data) if index not in drop_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e6488cf",
   "metadata": {
    "id": "FXHkZPOqo_ww"
   },
   "outputs": [],
   "source": [
    "encoder_input_train = drop_onesentence(encoder_input_train, drop_train)\n",
    "decoder_input_train = drop_onesentence(decoder_input_train, drop_train)\n",
    "decoder_target_train = drop_onesentence(decoder_target_train, drop_train)\n",
    "\n",
    "encoder_input_test = drop_onesentence(encoder_input_test, drop_test)\n",
    "decoder_input_test = drop_onesentence(decoder_input_test, drop_test)\n",
    "decoder_target_test = drop_onesentence(decoder_target_test, drop_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7cce3009",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mx9YQcrCpCtZ",
    "outputId": "3c4b8146-0e91-4b68-aef0-d30e5859dd31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 78416\n",
      "훈련 레이블의 개수 : 78416\n",
      "테스트 데이터의 개수 : 19603\n",
      "테스트 레이블의 개수 : 19603\n"
     ]
    }
   ],
   "source": [
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "805b0a71",
   "metadata": {
    "id": "HIICqhZ9pIdZ"
   },
   "outputs": [],
   "source": [
    "text_original_train = drop_onesentence(text_original_train, drop_train)\n",
    "text_original_test = drop_onesentence(text_original_test, drop_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9e6a33",
   "metadata": {
    "id": "0d3544cd"
   },
   "source": [
    "pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c7794ff",
   "metadata": {
    "id": "2EC-VTCjpNAE"
   },
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='pre')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='pre')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=headlines_max_len, padding='pre')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=headlines_max_len, padding='pre')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=headlines_max_len, padding='pre')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=headlines_max_len, padding='pre')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df1a0fa",
   "metadata": {
    "id": "b69b63f8"
   },
   "source": [
    "## - 인코더, 디코더 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "066e0f3e",
   "metadata": {
    "id": "5ZBv2lDZpQt5"
   },
   "outputs": [],
   "source": [
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "# encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
    "encoder_outputs, state_h3, state_c3 = encoder_lstm3(encoder_output2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5968bfbf",
   "metadata": {
    "id": "BIF4I6P2pofH"
   },
   "outputs": [],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "# decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h3, state_c3])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7fab6e8b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MUApaxfrpw2g",
    "outputId": "3330f928-795c-4161-95d5-5eff86d46542"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      896000      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    640000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 5000)   1285000     lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,660,104\n",
      "Trainable params: 4,660,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9bf6d1",
   "metadata": {
    "id": "cb2f67c4"
   },
   "source": [
    "# Step 3. 어텐션 메커니즘 사용하기 (추상적 요약)\n",
    "\n",
    "일반적인 seq2seq보다는 어텐션 메커니즘을 사용한 seq2seq를 사용하는 것이 더 나은 성능을 얻을 수 있어요. 실습 내용을 참고하여 어텐션 메커니즘을 사용한 seq2seq를 설계해 보세요.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269889c4",
   "metadata": {
    "id": "1642530f"
   },
   "source": [
    "## - 어텐션 레이어 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77ecdefc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-xvP2l1Op0DA",
    "outputId": "15ce577c-abc4-4027-d432-bb6374538e8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      896000      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    640000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AdditiveAttent (None, None, 256)    256         lstm_3[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 5000)   2565000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 5,940,360\n",
      "Trainable params: 5,940,360\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AdditiveAttention(name='attention_layer')\n",
    "\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out = attn_layer([decoder_outputs, encoder_outputs])\n",
    "\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345f1919",
   "metadata": {
    "id": "8b125f1c"
   },
   "source": [
    "## - 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61377fcb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jmuOJDGxp3Fv",
    "outputId": "302250e8-4ffa-4068-cdc6-75169b0e815e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "307/307 [==============================] - 37s 80ms/step - loss: 4.8041 - val_loss: 4.5273\n",
      "Epoch 2/50\n",
      "307/307 [==============================] - 24s 78ms/step - loss: 4.5443 - val_loss: 4.4902\n",
      "Epoch 3/50\n",
      "307/307 [==============================] - 25s 80ms/step - loss: 4.4434 - val_loss: 4.3216\n",
      "Epoch 4/50\n",
      "307/307 [==============================] - 25s 83ms/step - loss: 4.2754 - val_loss: 4.1566\n",
      "Epoch 5/50\n",
      "307/307 [==============================] - 26s 83ms/step - loss: 4.0867 - val_loss: 3.9816\n",
      "Epoch 6/50\n",
      "307/307 [==============================] - 25s 82ms/step - loss: 3.9044 - val_loss: 3.8189\n",
      "Epoch 7/50\n",
      "307/307 [==============================] - 25s 82ms/step - loss: 3.7178 - val_loss: 3.6685\n",
      "Epoch 8/50\n",
      "307/307 [==============================] - 25s 83ms/step - loss: 3.5622 - val_loss: 3.5560\n",
      "Epoch 9/50\n",
      "307/307 [==============================] - 25s 82ms/step - loss: 3.4253 - val_loss: 3.4621\n",
      "Epoch 10/50\n",
      "307/307 [==============================] - 25s 82ms/step - loss: 3.3022 - val_loss: 3.3762\n",
      "Epoch 11/50\n",
      "307/307 [==============================] - 25s 82ms/step - loss: 3.1843 - val_loss: 3.3030\n",
      "Epoch 12/50\n",
      "307/307 [==============================] - 25s 82ms/step - loss: 3.0752 - val_loss: 3.2324\n",
      "Epoch 13/50\n",
      "307/307 [==============================] - 25s 83ms/step - loss: 2.9730 - val_loss: 3.1706\n",
      "Epoch 14/50\n",
      "307/307 [==============================] - 25s 83ms/step - loss: 2.8814 - val_loss: 3.1249\n",
      "Epoch 15/50\n",
      "307/307 [==============================] - 25s 82ms/step - loss: 2.8010 - val_loss: 3.0910\n",
      "Epoch 16/50\n",
      "307/307 [==============================] - 25s 83ms/step - loss: 2.7273 - val_loss: 3.0474\n",
      "Epoch 17/50\n",
      "307/307 [==============================] - 25s 83ms/step - loss: 2.6616 - val_loss: 3.0401\n",
      "Epoch 18/50\n",
      "307/307 [==============================] - 25s 83ms/step - loss: 2.5992 - val_loss: 3.0378\n",
      "Epoch 19/50\n",
      "307/307 [==============================] - 25s 82ms/step - loss: 2.5419 - val_loss: 2.9807\n",
      "Epoch 20/50\n",
      "307/307 [==============================] - 25s 82ms/step - loss: 2.4902 - val_loss: 2.9781\n",
      "Epoch 21/50\n",
      "307/307 [==============================] - 25s 82ms/step - loss: 2.4388 - val_loss: 2.9810\n",
      "Epoch 22/50\n",
      "307/307 [==============================] - 25s 82ms/step - loss: 2.3923 - val_loss: 2.9517\n",
      "Epoch 23/50\n",
      "307/307 [==============================] - 25s 82ms/step - loss: 2.3503 - val_loss: 2.9664\n",
      "Epoch 24/50\n",
      "307/307 [==============================] - 25s 83ms/step - loss: 2.3099 - val_loss: 2.9404\n",
      "Epoch 25/50\n",
      "307/307 [==============================] - 25s 82ms/step - loss: 2.2715 - val_loss: 2.9453\n",
      "Epoch 26/50\n",
      "307/307 [==============================] - 25s 83ms/step - loss: 2.2338 - val_loss: 2.9701\n",
      "Epoch 00026: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=256, callbacks=[es], epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1805cebc",
   "metadata": {
    "id": "effa74c1"
   },
   "source": [
    "## - Loss 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6a8874b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "ecnf1A8kqfal",
    "outputId": "e921849e-a2bf-4ce4-8267-b06a11ee5d0b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef302c8",
   "metadata": {
    "id": "e7382102"
   },
   "source": [
    "# Step 4. 실제 결과와 요약문 비교하기 (추상적 요약)\n",
    "\n",
    "원래의 요약문(headlines 열)과 학습을 통해 얻은 추상적 요약의 결과를 비교해 보세요.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f13ffdd",
   "metadata": {
    "id": "1683bde2"
   },
   "source": [
    "## - 예측 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5be53da6",
   "metadata": {
    "id": "jR95jYrNq0Bi"
   },
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b507e2a2",
   "metadata": {
    "id": "Cr12zOsjq2Lz"
   },
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h3, state_c3])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99b5b7da",
   "metadata": {
    "id": "BHLS3r1tq4kL"
   },
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat)\n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7354149b",
   "metadata": {
    "id": "03d07917"
   },
   "source": [
    "## - 디코딩 시퀀스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3df31209",
   "metadata": {
    "id": "pTOBVEvzq7La"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if (sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (headlines_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3057b5c2",
   "metadata": {
    "id": "9b626a65"
   },
   "source": [
    "## - 정수 시퀀스를 텍스트 시퀀스로 변화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "27d5a961",
   "metadata": {
    "id": "Er1Vm68bq92p"
   },
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2headlines(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c1d99a",
   "metadata": {
    "id": "d78bd7ca"
   },
   "source": [
    "## - 실제/예측 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ba959bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w7iv-LY_rBSn",
    "outputId": "58d8254f-bb18-4b9e-b929-105d8ded5fc4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 토큰화된 원문: \n",
      "mark zuckerberg business card read ceo early years facebook according card designer idea came fact zuckerberg actually used phrase time style steve jobs born may zuckerberg turned today \n",
      "\n",
      "- 실제 요약: \n",
      "zuckerberg business card read ceo \n",
      "\n",
      "\n",
      "- 예측 요약: \n",
      " fb ceo takes dig yr old data fb ceo\n",
      "\n",
      "- 원문: \n",
      "Mark Zuckerberg once had a business card which read, \"I'm CEO, B*tch.\" during the early years of Facebook. According to the card's designer Bryan Veloso, the idea came from the fact that Zuckerberg actually used to utter the phrase at the time by emulating the style of Steve Jobs. Born on May 14, 1984, Zuckerberg turned 34 today.\n",
      "\n",
      "- 'SUMMARIZE' 요약: \n",
      "Mark Zuckerberg once had a business card which read, \"I'm CEO, B*tch.\" during the early years of Facebook.\n",
      "\n",
      "- 토큰화된 원문: \n",
      "delhi police seized residence year old known lady delhi due criminal background family eight sons criminal cases lodged reports said accused murder case absconding since september \n",
      "\n",
      "- 실제 요약: \n",
      "delhi lady family cases \n",
      "\n",
      "\n",
      "- 예측 요약: \n",
      " delhi police delhi man kills self police custody case\n",
      "\n",
      "- 원문: \n",
      "The Delhi Police has seized the residence of 62-year-old Bashreen, popularly known as 'Lady Don', in Delhi's Sangam Vihar due to her criminal background. Bashreen and her family of eight sons have over 100 criminal cases lodged against them, reports said. Bashreen, who is accused in a murder case, has been absconding since September 2017.\n",
      "\n",
      "- 'SUMMARIZE' 요약: \n",
      "Bashreen and her family of eight sons have over 100 criminal cases lodged against them, reports said.\n",
      "\n",
      "- 토큰화된 원문: \n",
      "several shipping firms japan come together develop remote controlled cargo vessels could launched according reports ships would use internet things data including weather conditions shipping information project aimed reduce number accidents sea removing potential human error \n",
      "\n",
      "- 실제 요약: \n",
      "japan firms launch cargo ships using internet things \n",
      "\n",
      "\n",
      "- 예측 요약: \n",
      " japan may cut new tech firms india st time\n",
      "\n",
      "- 원문: \n",
      "Several shipping firms in Japan have come together to develop remote-controlled cargo vessels that could be launched by 2025, according to reports. The ships would use the internet of things to gather data, including weather conditions and shipping information. The project is aimed to reduce the number of accidents at sea by removing the potential for human error.\n",
      "\n",
      "- 'SUMMARIZE' 요약: \n",
      "Several shipping firms in Japan have come together to develop remote-controlled cargo vessels that could be launched by 2025, according to reports.\n",
      "\n",
      "- 토큰화된 원문: \n",
      "maharashtra government planning form special cell ensure employees industries across state locals industries give percentage jobs locals avail offered state government officials said cell employee unions industries department industries minister subhash said \n",
      "\n",
      "- 실제 요약: \n",
      "maha govt cell ensure industries local employees \n",
      "\n",
      "\n",
      "- 예측 요약: \n",
      " maha govt plans stop food fund govt work reports\n",
      "\n",
      "- 원문: \n",
      "Maharashtra government is planning to form a special cell to ensure that 80% employees in industries across the state are locals. Industries are obligated to give this percentage of jobs to locals as most of them avail incentives offered by the state government, officials said. The cell will comprise employee unions and the industries department, Industries Minister Subhash Desai said.\n",
      "\n",
      "- 'SUMMARIZE' 요약: \n",
      "Maharashtra government is planning to form a special cell to ensure that 80% employees in industries across the state are locals.\n",
      "\n",
      "- 토큰화된 원문: \n",
      "external affairs minister sushma swaraj tagged tweet thursday read stuck mars food sent via running ii sent isro swaraj replied tweet saying even stuck mars indian embassy help \n",
      "\n",
      "- 실제 요약: \n",
      "indian embassy help even mars sushma tweets user \n",
      "\n",
      "\n",
      "- 예측 요약: \n",
      " indian origin minister tweets user robot tesla feet robot\n",
      "\n",
      "- 원문: \n",
      "External Affairs Minister Sushma Swaraj was tagged in a tweet on Thursday which read Ã¢ÂÂI am stuck on mars, food sent via Mangalyaan (987 days ago), is running out, when is Mangalyaan-II being sent ? @isro.Ã¢ÂÂ Swaraj replied to the tweet saying \"Even if you are stuck on the Mars, Indian Embassy there will help you.Ã¢ÂÂ\n",
      "\n",
      "- 'SUMMARIZE' 요약: \n",
      "\n",
      "\n",
      "- 토큰화된 원문: \n",
      "activist detained thursday allegedly red years pulling stunt authorities forced pool prevent damage meanwhile accused said protesting corruption added protest cry dead \n",
      "\n",
      "- 실제 요약: \n",
      "activist turns red protest \n",
      "\n",
      "\n",
      "- 예측 요약: \n",
      " man gets st time since arrest london police arrest\n",
      "\n",
      "- 원문: \n",
      "An activist was detained on Thursday after allegedly pouring red dye into Rome's Trevi Fountain, 10 years after pulling the same stunt. Authorities were forced to drain the fountain pool to prevent any damage from the dye. Meanwhile, the accused, Graziano Cecchini said he was protesting against corruption and added that his protest was a \"cry that Rome isn't dead\".n\n",
      "\n",
      "- 'SUMMARIZE' 요약: \n",
      "An activist was detained on Thursday after allegedly pouring red dye into Rome's Trevi Fountain, 10 years after pulling the same stunt.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 6):\n",
    "    text = seq2text(encoder_input_test[i])\n",
    "    print(\"- 토큰화된 원문: \\n{}\\n\".format(text))\n",
    "    print(\"- 실제 요약: \\n{}\\n\".format(seq2headlines(decoder_input_test[i])))\n",
    "    print(\"\\n- 예측 요약: \\n{}\\n\".format(decode_sequence(encoder_input_test[i].reshape(1, text_max_len))))\n",
    "    print(\"- 원문: \\n{}\\n\".format(text_original_test[i]))\n",
    "    print(\"- 'SUMMARIZE' 요약: \\n{}\\n\".format(summarize(text_original_test[i], ratio=0.4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc7175b",
   "metadata": {
    "id": "1b627c4a"
   },
   "source": [
    "# Step 5. Summa을 이용해서 추출적 요약해보기\n",
    "\n",
    "추상적 요약은 추출적 요약과는 달리 문장의 표현력을 다양하게 가져갈 수 있지만, 추출적 요약에 비해서 난이도가 높아요. 반대로 말하면 추출적 요약은 추상적 요약에 비해 난이도가 낮고 기존 문장에서 문장을 꺼내오는 것이므로 잘못된 요약이 나올 가능성이 낮아요.\n",
    "\n",
    "Summa의 summarize를 사용하여 추출적 요약을 해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8a53c4",
   "metadata": {
    "id": "656f6861",
    "outputId": "27a1aa1d-75f1-4fd8-8a01-452513922bd1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_org['text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce480b7",
   "metadata": {
    "id": "748c9087",
    "outputId": "d4cda591-7350-4ac9-dcf8-879b3ef85d24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upGrad's Online Power Learning has powered 3 lakh+ careers.\n"
     ]
    }
   ],
   "source": [
    "print(summarize(data_org['text'].iloc[0], ratio=0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3ff64e",
   "metadata": {
    "id": "45348e15",
    "outputId": "ea8dbe0d-5382-47e6-d350-ad212b19a417"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike.\n",
      "upGrad's Online Power Learning has powered 3 lakh+ careers.\n"
     ]
    }
   ],
   "source": [
    "print(summarize(data_org['text'].iloc[0], words=20))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
